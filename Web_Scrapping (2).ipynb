{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Amsterdam Apartments**"
      ],
      "metadata": {
        "id": "uTebJUjK5NtC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8htRv36Ly-c"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from csv import writer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7NdiuCGNbqL"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.pararius.com/apartments/amsterdam?ac=1\"\n",
        "page = requests.get(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMFLuSAxNtuq"
      },
      "outputs": [],
      "source": [
        "soup = BeautifulSoup(page.content,'html.parser')\n",
        "soup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lists = soup.find_all('section',class_ = 'listing-search-item')"
      ],
      "metadata": {
        "id": "k_5rOlfKkkc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDR073FmN8yQ"
      },
      "outputs": [],
      "source": [
        "lists = soup.find_all('section',class_ = 'listing-search-item') # _ is used after class for html class\n",
        "\n",
        "\n",
        "with open('housing_scrape.csv','w',newline='')as f:   # w is mode : write   r : read etc\n",
        "  thewriter = writer(f)\n",
        "  header = ['Title','Location','Area','Price','Rooms']\n",
        "  thewriter.writerow(header)\n",
        "  for list in lists:\n",
        "    Title = list.find('a',class_=\"listing-search-item__link--title\").text.replace('\\n','')\n",
        "    Location = list.find('div',class_='listing-search-item__sub-title').text.replace('\\n','')\n",
        "    Area = list.find('li',class_=\"illustrated-features__item--surface-area\").text.replace('\\n','')\n",
        "    Price = list.find('div',class_='listing-search-item__price').text.replace('\\n','')\n",
        "    Rooms = list.find('li',class_='illustrated-features__item--number-of-rooms').text.replace('\\n','')\n",
        "    #Interior = list.find('li',class_=\"illustrated-features__item--interior\").text\n",
        "\n",
        "    info = [Title,Location,Area,Price,Rooms]\n",
        "    thewriter.writerow(info) \n",
        "    #print(info)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GL COURSES**"
      ],
      "metadata": {
        "id": "g4sgG3_ix736"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url1 = \"https://www.mygreatlearning.com/data-science/free-courses?p=5#subject-courses-section\"\n",
        "page1 = requests.get(url1)"
      ],
      "metadata": {
        "id": "jQmgezZKg9az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup1 = BeautifulSoup(page1.content,'html.parser')\n",
        "#soup1"
      ],
      "metadata": {
        "id": "42fJfwkhhHFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lists1 = soup1.find_all('div',class_=\"subject-course-card\")"
      ],
      "metadata": {
        "id": "WLGFjIh4kHgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lists1"
      ],
      "metadata": {
        "id": "V5uS4aqya05e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('GLcourses_scrape.csv','w',newline='')as f:\n",
        "  thewriter = writer(f)\n",
        "  header = ['Course','Rating','Level']\n",
        "  thewriter.writerow(header)  \n",
        "  for list in lists1:\n",
        "    Course = list.find('div',class_='course-name').text.replace('\\n      ','')\n",
        "    #Time = list.find('div',class_='course-info').text\n",
        "    Rating = list.find('span',class_='course-ratings-label').text.replace('\\n      ','')\n",
        "    Level = list.find('div',class_='dot').text.replace('\\n        ','')\n",
        "    info = [Course,Rating,Level]\n",
        "    thewriter.writerow(info)\n",
        "    #print(info)"
      ],
      "metadata": {
        "id": "OlaEsJAHqMNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas \n",
        "df1 = pandas.read_csv(\"/content/GLcourses_scrape.csv\")\n",
        "df2 = pandas.read_csv(\"/content/GLcourses_scrape2.csv\")\n",
        "df3 = pandas.read_csv(\"/content/GLcourses_scrape3.csv\")\n",
        "df4 = pandas.read_csv(\"/content/GLcourses_scrape4.csv\")"
      ],
      "metadata": {
        "id": "P22e-iAkzPgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pandas.concat([df1,df2,df3,df4],axis=0,ignore_index=True)"
      ],
      "metadata": {
        "id": "Cl8wZx9v2PhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Hfh3GPit2kR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('GLcourses.csv') # index=None"
      ],
      "metadata": {
        "id": "FUFghT974h1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BOOKS** : Multiple page scrapping"
      ],
      "metadata": {
        "id": "X80k3v1qari2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from csv import writer"
      ],
      "metadata": {
        "id": "o0FU1-uNatlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Books.csv','w',newline='')as f:\n",
        "  thewrite = writer(f)\n",
        "  header = ['Title','Rating','Price']\n",
        "  thewrite.writerow(header)\n",
        "  for i in range(1,51):\n",
        "    url = f\"https://books.toscrape.com/catalogue/page-{i}.html\" # takes i and loops it\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content,'html.parser')\n",
        "    articles = soup.find_all('article',class_='product_pod')\n",
        "\n",
        "    for a in articles:\n",
        "      image = a.find('img')\n",
        "      title = image.attrs['alt']  # gets the data present insiode the image attribute 'alt'\n",
        "      #print(title)\n",
        "      star = a.find('p')\n",
        "      star = star['class'][1] # index 1 \n",
        "      #print(star)\n",
        "      price = a.find('p',class_='price_color').text # returns in string format\n",
        "      price = float(price[1:]) # gets from index 1  > excludes symbol converts to number\n",
        "      #print(price)\n",
        "      info = [title,star,price]\n",
        "      thewrite.writerow(info)\n"
      ],
      "metadata": {
        "id": "w9op8XZ-fUaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scrapping - 2**"
      ],
      "metadata": {
        "id": "f-bvJH6b_FJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from csv import writer"
      ],
      "metadata": {
        "id": "u4sNhDR_ZpAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.nike.com/au/w/mens-shoes-nik1zy7ok'\n",
        "page = requests.get(url)\n",
        "soup = BeautifulSoup(page.content,'html.parser')"
      ],
      "metadata": {
        "id": "HaIUZAGkZvDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lists = soup.find_all('div',class_='product-card__body')"
      ],
      "metadata": {
        "id": "0K1yfeyjZ-Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Shoes1.csv','w') as f:\n",
        "  dwriter = writer(f)\n",
        "  header = ['Title','Sub_title','Colours','Price']\n",
        "  dwriter.writerow(header)\n",
        "  for list in lists:\n",
        "    Title = list.find('div',class_='product-card__title').text\n",
        "    Sub_title = list.find('div',class_='product-card__subtitle').text\n",
        "    Price = list.find('div',class_='product-card__price').text\n",
        "    Colours = list.find('div',class_='product-card__count-item').text\n",
        "    info = [Title,Sub_title,Colours,Price]\n",
        "    dwriter.writerow(info)\n",
        "    #print(Colours)"
      ],
      "metadata": {
        "id": "nBz_lw3bbrbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}